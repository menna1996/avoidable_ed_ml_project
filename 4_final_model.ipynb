{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "debba0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded modeling_dataset_clean.parquet\n",
      "Columns: ['AGE_AT_END_REF_YR', 'SEX_IDENT_CD', 'BENE_RACE_CD', 'YEAR', 'total_paid_amt', 'primary_dx_chronic_flag', 'bodysystem_respiratory', 'bodysystem_circulatory', 'bodysystem_infectious', 'bodysystem_digestive', 'bodysystem_mentalbehavioral', 'bodysystem_musculoskeletal', 'bodysystem_neoplasms', 'bodysystem_nervoussystem', 'bodysystem_injurypoisoning', 'bodysystem_skin', 'bodysystem_genitourinary', 'bodysystem_endocrine', 'bodysystem_bloodimmune', 'bodysystem_symptoms', 'bodysystem_externalcauses', 'bodysystem_congenital', 'bodysystem_perinatal', 'bodysystem_pregnancy', 'bodysystem_dental', 'bodysystem_eye', 'bodysystem_ear', 'bodysystem_healthstatus', 'bodysystem_unacceptable', 'Avoidable_ED_Visit']\n",
      "âœ… Detected target column: Avoidable_ED_Visit\n",
      "âœ… X_train shape: (6047, 29)\n",
      "âœ… y_train shape: (6047,)\n",
      "âœ… Best run: Exp2_RandomForest\n",
      "âœ… Cleaned params: {'max_depth': 20, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "âœ… Final model fitted.\n",
      "âœ… Saved final_avoidable_ed_model.joblib\n",
      "âœ… Input features: ['AGE_AT_END_REF_YR', 'SEX_IDENT_CD', 'BENE_RACE_CD', 'YEAR', 'total_paid_amt', 'primary_dx_chronic_flag', 'bodysystem_respiratory', 'bodysystem_circulatory', 'bodysystem_infectious', 'bodysystem_digestive', 'bodysystem_mentalbehavioral', 'bodysystem_musculoskeletal', 'bodysystem_neoplasms', 'bodysystem_nervoussystem', 'bodysystem_injurypoisoning', 'bodysystem_skin', 'bodysystem_genitourinary', 'bodysystem_endocrine', 'bodysystem_bloodimmune', 'bodysystem_symptoms', 'bodysystem_externalcauses', 'bodysystem_congenital', 'bodysystem_perinatal', 'bodysystem_pregnancy', 'bodysystem_dental', 'bodysystem_eye', 'bodysystem_ear', 'bodysystem_healthstatus', 'bodysystem_unacceptable']\n",
      "\n",
      "class EDVisitInput(BaseModel):\n",
      "    AGE_AT_END_REF_YR: float\n",
      "    SEX_IDENT_CD: float\n",
      "    BENE_RACE_CD: float\n",
      "    YEAR: float\n",
      "    total_paid_amt: float\n",
      "    primary_dx_chronic_flag: float\n",
      "    bodysystem_respiratory: float\n",
      "    bodysystem_circulatory: float\n",
      "    bodysystem_infectious: float\n",
      "    bodysystem_digestive: float\n",
      "    bodysystem_mentalbehavioral: float\n",
      "    bodysystem_musculoskeletal: float\n",
      "    bodysystem_neoplasms: float\n",
      "    bodysystem_nervoussystem: float\n",
      "    bodysystem_injurypoisoning: float\n",
      "    bodysystem_skin: float\n",
      "    bodysystem_genitourinary: float\n",
      "    bodysystem_endocrine: float\n",
      "    bodysystem_bloodimmune: float\n",
      "    bodysystem_symptoms: float\n",
      "    bodysystem_externalcauses: float\n",
      "    bodysystem_congenital: float\n",
      "    bodysystem_perinatal: float\n",
      "    bodysystem_pregnancy: float\n",
      "    bodysystem_dental: float\n",
      "    bodysystem_eye: float\n",
      "    bodysystem_ear: float\n",
      "    bodysystem_healthstatus: float\n",
      "    bodysystem_unacceptable: float\n",
      "\n",
      "âœ… main.py generated.\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# FINAL MODEL + FASTAPI GENERATION SCRIPT (ONE PAGE)\n",
    "# =========================================================\n",
    "\n",
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from custom_transformers import Log1pTransformer\n",
    "from pydantic import BaseModel\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 0. Load modeling dataset and create X_train / y_train\n",
    "# ---------------------------------------------------------\n",
    "df = pd.read_parquet(\"modeling_dataset_clean.parquet\")\n",
    "print(\"âœ… Loaded modeling_dataset_clean.parquet\")\n",
    "print(\"Columns:\", df.columns.tolist())\n",
    "\n",
    "# Dynamically detect target column (ONLY binary col, else last)\n",
    "binary_cols = [c for c in df.columns if df[c].dropna().isin([0, 1]).all()]\n",
    "if len(binary_cols) == 1:\n",
    "    target_col = binary_cols[0]\n",
    "else:\n",
    "    target_col = df.columns[-1]\n",
    "\n",
    "print(f\"âœ… Detected target column: {target_col}\")\n",
    "\n",
    "X = df.drop(target_col, axis=1)\n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"âœ… X_train shape:\", X_train.shape)\n",
    "print(\"âœ… y_train shape:\", y_train.shape)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Connect to MLflow and find best run\n",
    "# ---------------------------------------------------------\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/menna1996/avoidable_ed_ml_project.mlflow\")\n",
    "client = MlflowClient()\n",
    "\n",
    "experiment = client.get_experiment_by_name(\"Final_Project_Experiments\")\n",
    "runs = client.search_runs(experiment_ids=[experiment.experiment_id])\n",
    "\n",
    "records = []\n",
    "for run in runs:\n",
    "    f1 = run.data.metrics.get(\"test_f1\")\n",
    "    if f1 is not None:\n",
    "        records.append({\n",
    "            \"run_id\": run.info.run_id,\n",
    "            \"run_name\": run.data.tags.get(\"mlflow.runName\", run.info.run_id),\n",
    "            \"test_f1\": f1\n",
    "        })\n",
    "\n",
    "df_runs = pd.DataFrame(records).sort_values(\"test_f1\", ascending=False)\n",
    "best_run = df_runs.iloc[0]\n",
    "\n",
    "best_run_id = best_run[\"run_id\"]\n",
    "best_run_name = best_run[\"run_name\"]\n",
    "\n",
    "print(\"âœ… Best run:\", best_run_name)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Extract and clean hyperparameters\n",
    "# ---------------------------------------------------------\n",
    "run_data = client.get_run(best_run_id)\n",
    "raw_params = run_data.data.params\n",
    "\n",
    "clean_params = {}\n",
    "for k, v in raw_params.items():\n",
    "    if k.startswith(\"clf__\"):\n",
    "        k = k.replace(\"clf__\", \"\")\n",
    "    if k in [\"n_estimators\", \"max_depth\", \"min_samples_split\", \"min_samples_leaf\"]:\n",
    "        clean_params[k] = int(v)\n",
    "    elif v in [\"True\", \"False\"]:\n",
    "        clean_params[k] = (v == \"True\")\n",
    "    else:\n",
    "        clean_params[k] = v\n",
    "\n",
    "print(\"âœ… Cleaned params:\", clean_params)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. EXACT feature lists from your experiment\n",
    "# ---------------------------------------------------------\n",
    "numeric_features = [\n",
    "    \"AGE_AT_END_REF_YR\",\n",
    "    \"total_paid_amt\",\n",
    "    \"primary_dx_chronic_flag\",\n",
    "    \"bodysystem_respiratory\",\n",
    "    \"bodysystem_circulatory\",\n",
    "    \"bodysystem_infectious\",\n",
    "    \"bodysystem_digestive\",\n",
    "    \"bodysystem_mentalbehavioral\",\n",
    "    \"bodysystem_musculoskeletal\",\n",
    "    \"bodysystem_neoplasms\",\n",
    "    \"bodysystem_nervoussystem\",\n",
    "    \"bodysystem_injurypoisoning\",\n",
    "    \"bodysystem_skin\",\n",
    "    \"bodysystem_genitourinary\",\n",
    "    \"bodysystem_endocrine\",\n",
    "    \"bodysystem_bloodimmune\",\n",
    "    \"bodysystem_symptoms\",\n",
    "    \"bodysystem_externalcauses\",\n",
    "    \"bodysystem_congenital\",\n",
    "    \"bodysystem_perinatal\",\n",
    "    \"bodysystem_pregnancy\",\n",
    "    \"bodysystem_dental\",\n",
    "    \"bodysystem_eye\",\n",
    "    \"bodysystem_ear\",\n",
    "    \"bodysystem_healthstatus\",\n",
    "    \"bodysystem_unacceptable\",\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    \"SEX_IDENT_CD\",\n",
    "    \"BENE_RACE_CD\",\n",
    "    \"YEAR\"\n",
    "]\n",
    "\n",
    "missing_in_data = [c for c in numeric_features + categorical_features if c not in X_train.columns]\n",
    "if missing_in_data:\n",
    "    print(\"âŒ ERROR: Missing features:\", missing_in_data)\n",
    "    raise ValueError(\"Feature mismatch between experiment and modeling_dataset_clean.parquet\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Rebuild preprocessing pipeline\n",
    "# ---------------------------------------------------------\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"log1p\", Log1pTransformer()),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. Rebuild final model\n",
    "# ---------------------------------------------------------\n",
    "rf_final = RandomForestClassifier(\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    **clean_params,\n",
    ")\n",
    "\n",
    "final_pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"clf\", rf_final),\n",
    "])\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 6. Fit final model\n",
    "# ---------------------------------------------------------\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "print(\"âœ… Final model fitted.\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 7. Save final model\n",
    "# ---------------------------------------------------------\n",
    "joblib.dump(final_pipeline, \"final_avoidable_ed_model.joblib\")\n",
    "print(\"âœ… Saved final_avoidable_ed_model.joblib\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 8. Extract input features for FastAPI\n",
    "# ---------------------------------------------------------\n",
    "input_features = preprocessor.feature_names_in_\n",
    "print(\"âœ… Input features:\", list(input_features))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 9. Generate FastAPI schema\n",
    "# ---------------------------------------------------------\n",
    "fields = \"\\n\".join([f\"    {feat}: float\" for feat in input_features])\n",
    "\n",
    "schema_text = f\"\"\"\n",
    "class EDVisitInput(BaseModel):\n",
    "{fields}\n",
    "\"\"\"\n",
    "\n",
    "print(schema_text)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 10. Generate main.py (FastAPI app) â€” FIXED VERSION\n",
    "# ---------------------------------------------------------\n",
    "main_py = f\"\"\"\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "model = joblib.load(\"final_avoidable_ed_model.joblib\")\n",
    "\n",
    "class EDVisitInput(BaseModel):\n",
    "{fields}\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/\")\n",
    "def root():\n",
    "    return {{\"message\": \"Avoidable ED Prediction API\"}}\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(data: EDVisitInput):\n",
    "    try:\n",
    "        df = pd.DataFrame([data.dict()])\n",
    "        print(\"âœ… Received input:\", df.to_dict(orient=\"records\")[0])\n",
    "\n",
    "        df.columns = df.columns.str.strip()\n",
    "\n",
    "        categorical_cols = [\"SEX_IDENT_CD\", \"BENE_RACE_CD\", \"YEAR\"]\n",
    "        for col in categorical_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(str)\n",
    "\n",
    "        df.fillna(\"missing\", inplace=True)\n",
    "\n",
    "        pred = model.predict(df)[0]\n",
    "        prob = model.predict_proba(df)[0][1]\n",
    "\n",
    "        print(\"âœ… Prediction:\", pred, \"Probability:\", prob)\n",
    "        return {{\"prediction\": int(pred), \"probability\": float(prob)}}\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"âŒ Prediction error:\", str(e))\n",
    "        raise HTTPException(status_code=500, detail=\"Prediction failed\")\n",
    "\"\"\"\n",
    "\n",
    "with open(\"main.py\", \"w\") as f:\n",
    "    f.write(main_py)\n",
    "\n",
    "print(\"âœ… main.py generated.\")\n",
    "# =========================================================\n",
    "# END OF ONE-PAGE SCRIPT\n",
    "# ========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aca856f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded dataset\n",
      "âœ… Target column: Avoidable_ED_Visit\n",
      "âœ… Model loaded\n",
      "âœ… Expected features: ['AGE_AT_END_REF_YR', 'SEX_IDENT_CD', 'BENE_RACE_CD', 'YEAR', 'total_paid_amt', 'primary_dx_chronic_flag', 'bodysystem_respiratory', 'bodysystem_circulatory', 'bodysystem_infectious', 'bodysystem_digestive', 'bodysystem_mentalbehavioral', 'bodysystem_musculoskeletal', 'bodysystem_neoplasms', 'bodysystem_nervoussystem', 'bodysystem_injurypoisoning', 'bodysystem_skin', 'bodysystem_genitourinary', 'bodysystem_endocrine', 'bodysystem_bloodimmune', 'bodysystem_symptoms', 'bodysystem_externalcauses', 'bodysystem_congenital', 'bodysystem_perinatal', 'bodysystem_pregnancy', 'bodysystem_dental', 'bodysystem_eye', 'bodysystem_ear', 'bodysystem_healthstatus', 'bodysystem_unacceptable']\n",
      "âœ… No missing features\n",
      "âœ… No extra features\n",
      "âœ… Single prediction OK: 0 0.038439883318979254\n",
      "âœ… Batch prediction OK\n",
      "âœ… No NaNs in predictions\n",
      "\n",
      "ðŸŽ‰ FINAL CHECK COMPLETE â€” Model is deploymentâ€‘ready ðŸŽ‰\n"
     ]
    }
   ],
   "source": [
    "# Validation \n",
    "\n",
    "!pip install uvicorn[standard]\n",
    "\n",
    "from custom_transformers import Log1pTransformer\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -------------------------------\n",
    "# Load dataset\n",
    "# -------------------------------\n",
    "df = pd.read_parquet(\"modeling_dataset_clean.parquet\")\n",
    "print(\"âœ… Loaded dataset\")\n",
    "\n",
    "# Detect target column (binary or last column)\n",
    "binary_cols = [c for c in df.columns if df[c].dropna().isin([0,1]).all()]\n",
    "target_col = binary_cols[0] if len(binary_cols)==1 else df.columns[-1]\n",
    "print(\"âœ… Target column:\", target_col)\n",
    "\n",
    "X = df.drop(target_col, axis=1)\n",
    "y = df[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# -------------------------------\n",
    "# Load model\n",
    "# -------------------------------\n",
    "model = joblib.load(\"final_avoidable_ed_model.joblib\")\n",
    "print(\"âœ… Model loaded\")\n",
    "\n",
    "# -------------------------------\n",
    "# Check feature alignment\n",
    "# -------------------------------\n",
    "expected = list(model.named_steps[\"preprocess\"].feature_names_in_)\n",
    "missing = [c for c in expected if c not in X_train.columns]\n",
    "extra = [c for c in X_train.columns if c not in expected]\n",
    "\n",
    "print(\"âœ… Expected features:\", expected)\n",
    "print(\"âŒ Missing:\", missing) if missing else print(\"âœ… No missing features\")\n",
    "print(\"âš ï¸ Extra:\", extra) if extra else print(\"âœ… No extra features\")\n",
    "\n",
    "# -------------------------------\n",
    "# Prediction tests\n",
    "# -------------------------------\n",
    "sample = X_train.iloc[[0]]\n",
    "pred = model.predict(sample)[0]\n",
    "prob = model.predict_proba(sample)[0][1]\n",
    "print(\"âœ… Single prediction OK:\", pred, prob)\n",
    "\n",
    "preds = model.predict(X_train.head(50))\n",
    "probs = model.predict_proba(X_train.head(50))[:,1]\n",
    "print(\"âœ… Batch prediction OK\")\n",
    "\n",
    "# -------------------------------\n",
    "# NaN check\n",
    "# -------------------------------\n",
    "if np.isnan(preds).any() or np.isnan(probs).any():\n",
    "    print(\"âŒ NaNs found\")\n",
    "else:\n",
    "    print(\"âœ… No NaNs in predictions\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ FINAL CHECK COMPLETE â€” Model is deploymentâ€‘ready ðŸŽ‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c44f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uvicorn[standard] in c:\\users\\bruck\\anaconda3\\lib\\site-packages (0.38.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\bruck\\anaconda3\\lib\\site-packages (from uvicorn[standard]) (8.1.8)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\bruck\\anaconda3\\lib\\site-packages (from uvicorn[standard]) (0.16.0)\n",
      "Requirement already satisfied: colorama>=0.4 in c:\\users\\bruck\\anaconda3\\lib\\site-packages (from uvicorn[standard]) (0.4.6)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard])\n",
      "  Downloading httptools-0.7.1-cp313-cp313-win_amd64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\bruck\\anaconda3\\lib\\site-packages (from uvicorn[standard]) (1.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\bruck\\anaconda3\\lib\\site-packages (from uvicorn[standard]) (6.0.3)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard])\n",
      "  Downloading watchfiles-1.1.1-cp313-cp313-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard])\n",
      "  Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: anyio>=3.0.0 in c:\\users\\bruck\\anaconda3\\lib\\site-packages (from watchfiles>=0.13->uvicorn[standard]) (4.7.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\bruck\\anaconda3\\lib\\site-packages (from anyio>=3.0.0->watchfiles>=0.13->uvicorn[standard]) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\bruck\\anaconda3\\lib\\site-packages (from anyio>=3.0.0->watchfiles>=0.13->uvicorn[standard]) (1.3.0)\n",
      "Downloading httptools-0.7.1-cp313-cp313-win_amd64.whl (85 kB)\n",
      "Downloading watchfiles-1.1.1-cp313-cp313-win_amd64.whl (288 kB)\n",
      "Downloading websockets-15.0.1-cp313-cp313-win_amd64.whl (176 kB)\n",
      "Installing collected packages: websockets, httptools, watchfiles\n",
      "\n",
      "   ---------------------------------------- 0/3 [websockets]\n",
      "   ---------------------------------------- 3/3 [watchfiles]\n",
      "\n",
      "Successfully installed httptools-0.7.1 watchfiles-1.1.1 websockets-15.0.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install uvicorn[standard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cb6375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your Docker image - docker build -t avoidable-ed-api .\n",
    "\n",
    "# RUN THE container in a terminal - docker run -p 8000:8000 avoidable-ed-api\n",
    "\n",
    "# running in the background - docker run -d -p 8000:8000 avoidable-ed-api\n",
    "\n",
    "# Push to Docker Hub\n",
    "        # docker tag avoidable-ed-api yourusername/avoidable-ed-api\n",
    "        # docker push yourusername/avoidable-ed-api\n",
    "\n",
    "# Test - http://localhost:8000/docs\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
